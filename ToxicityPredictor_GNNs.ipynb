{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcacac9",
   "metadata": {},
   "source": [
    "# Building Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1edbe6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rdkit in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2025.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from rdkit) (2.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from rdkit) (11.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install rdkit\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd7f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (0.24.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2.7.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.11.18)\n",
      "Requirement already satisfied: fsspec in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (7.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "%pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52323a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from torch_geometric.utils import from_smiles\n",
    "\n",
    "CONFIG = {\n",
    "    'data_dir': './processed_tox21',\n",
    "    'hidden_channels': 128,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 0,\n",
    "    'epochs': 50,\n",
    "    'patience': 8,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Automatically detects if you have a GPU\n",
    "print(f\"Using device: {CONFIG['device']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb190d6a",
   "metadata": {},
   "source": [
    "Load data from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cfc6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6258 | Validation: 782 | Test: 783\n"
     ]
    }
   ],
   "source": [
    "def load_split(name):\n",
    "    path = os.path.join(CONFIG['data_dir'], f'tox21_{name}.pkl')\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train = load_split('train')\n",
    "data_validation = load_split('validation')\n",
    "data_test = load_split('test')\n",
    "\n",
    "print(f\"Train: {len(data_train['smiles'])} | Validation: {len(data_validation['smiles'])} | Test: {len(data_test['smiles'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff422e",
   "metadata": {},
   "source": [
    "Convert SMILES to GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5af06857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(smi, labels):\n",
    "    try:\n",
    "        data = from_smiles(smi)\n",
    "        data.y = torch.tensor(labels, dtype=torch.float)\n",
    "        return data\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_dataset(smiles_list, label_matrix):\n",
    "    dataset = []\n",
    "    for smi, lbl in zip(smiles_list, label_matrix):\n",
    "        g = build_graph(smi, lbl)\n",
    "        if g is not None:\n",
    "            dataset.append(g)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "873e1893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Data\n",
      "Train: 6258 | Validation: 782 | Test: 783\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(data_train['smiles'], data_train['labels'])\n",
    "validation_dataset = make_dataset(data_validation['smiles'], data_validation['labels'])\n",
    "test_dataset = make_dataset(data_test['smiles'], data_test['labels'])\n",
    "\n",
    "print(f\"Graphs Data\")\n",
    "print(f\"Train: {len(train_dataset)} | Validation: {len(validation_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac301c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = CONFIG['batch_size'], shuffle = True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size = CONFIG['batch_size'])\n",
    "test_loader = DataLoader(test_dataset, batch_size = CONFIG['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed950470",
   "metadata": {},
   "source": [
    "Class for GNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49f58632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, model_type='GCN', num_layers=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        self.convs = nn.ModuleList()\n",
    "        if model_type == 'GCN':\n",
    "            # Aggregates information from neighboring atoms\n",
    "            self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "            for _ in range(num_layers-1):\n",
    "                self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        elif model_type == 'GAT':\n",
    "            # Learns to weight each neighbour\n",
    "            self.convs.append(GATConv(in_channels, hidden_channels, heads=4, concat=False))\n",
    "            for _ in range(num_layers-1):\n",
    "                self.convs.append(GATConv(hidden_channels, hidden_channels, heads=4, concat=False))\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'GCN' or 'GAT'\")\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels//2, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = torch.relu(x)\n",
    "            x = nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56812b35",
   "metadata": {},
   "source": [
    "Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99df133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_bce_loss(logits, labels):\n",
    "    mask = ~torch.isnan(labels)\n",
    "    if mask.sum() == 0:\n",
    "        return torch.tensor(0.0, device=logits.device)\n",
    "    labels_filled = torch.where(mask, labels, torch.zeros_like(labels))\n",
    "    loss = nn.BCEWithLogitsLoss(reduction='none')(logits, labels_filled)\n",
    "    loss = loss * mask.float()\n",
    "    return loss.sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25e1c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data.x = data.x.to(torch.float)\n",
    "        data.edge_index = data.edge_index.to(torch.long)\n",
    "        if hasattr(data, \"edge_attr\") and data.edge_attr is not None:\n",
    "            data.edge_attr = data.edge_attr.to(torch.float)\n",
    "        data.y = data.y.to(torch.float)\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        if data.y.dim() == 1:\n",
    "            data.y = data.y.view(-1, logits.size(1))\n",
    "\n",
    "        loss = masked_bce_loss(logits, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2633cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data.x = data.x.to(torch.float)\n",
    "            data.edge_index = data.edge_index.to(torch.long)\n",
    "            if hasattr(data, \"edge_attr\") and data.edge_attr is not None:\n",
    "                data.edge_attr = data.edge_attr.to(torch.float)\n",
    "            data.y = data.y.to(torch.float)\n",
    "\n",
    "            data = data.to(device)\n",
    "            \n",
    "            logits = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "            if data.y.dim() == 1:\n",
    "                data.y = data.y.view(-1, logits.size(1))\n",
    "\n",
    "            loss = masked_bce_loss(logits, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9439db8",
   "metadata": {},
   "source": [
    "Train and Evaluate GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68009d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN\n",
      "GCN | Epoch 001 Train Loss: 0.3125 | Val Loss: 0.2506\n",
      "GCN | Epoch 002 Train Loss: 0.2519 | Val Loss: 0.2427\n",
      "GCN | Epoch 003 Train Loss: 0.2483 | Val Loss: 0.2387\n",
      "GCN | Epoch 004 Train Loss: 0.2452 | Val Loss: 0.2370\n",
      "GCN | Epoch 005 Train Loss: 0.2429 | Val Loss: 0.2359\n",
      "GCN | Epoch 006 Train Loss: 0.2405 | Val Loss: 0.2334\n",
      "GCN | Epoch 007 Train Loss: 0.2392 | Val Loss: 0.2382\n",
      "GCN | Epoch 008 Train Loss: 0.2351 | Val Loss: 0.2305\n",
      "GCN | Epoch 009 Train Loss: 0.2334 | Val Loss: 0.2345\n",
      "GCN | Epoch 010 Train Loss: 0.2335 | Val Loss: 0.2314\n",
      "GCN | Epoch 011 Train Loss: 0.2331 | Val Loss: 0.2345\n",
      "GCN | Epoch 012 Train Loss: 0.2324 | Val Loss: 0.2289\n",
      "GCN | Epoch 013 Train Loss: 0.2318 | Val Loss: 0.2261\n",
      "GCN | Epoch 014 Train Loss: 0.2310 | Val Loss: 0.2311\n",
      "GCN | Epoch 015 Train Loss: 0.2317 | Val Loss: 0.2252\n",
      "GCN | Epoch 016 Train Loss: 0.2312 | Val Loss: 0.2284\n",
      "GCN | Epoch 017 Train Loss: 0.2301 | Val Loss: 0.2291\n",
      "GCN | Epoch 018 Train Loss: 0.2294 | Val Loss: 0.2274\n",
      "GCN | Epoch 019 Train Loss: 0.2286 | Val Loss: 0.2255\n",
      "GCN | Epoch 020 Train Loss: 0.2306 | Val Loss: 0.2257\n",
      "GCN | Epoch 021 Train Loss: 0.2280 | Val Loss: 0.2258\n",
      "GCN | Epoch 022 Train Loss: 0.2275 | Val Loss: 0.2241\n",
      "GCN | Epoch 023 Train Loss: 0.2285 | Val Loss: 0.2228\n",
      "GCN | Epoch 024 Train Loss: 0.2277 | Val Loss: 0.2250\n",
      "GCN | Epoch 025 Train Loss: 0.2251 | Val Loss: 0.2223\n",
      "GCN | Epoch 026 Train Loss: 0.2253 | Val Loss: 0.2265\n",
      "GCN | Epoch 027 Train Loss: 0.2260 | Val Loss: 0.2230\n",
      "GCN | Epoch 028 Train Loss: 0.2264 | Val Loss: 0.2223\n",
      "GCN | Epoch 029 Train Loss: 0.2254 | Val Loss: 0.2210\n",
      "GCN | Epoch 030 Train Loss: 0.2253 | Val Loss: 0.2207\n",
      "GCN | Epoch 031 Train Loss: 0.2248 | Val Loss: 0.2215\n",
      "GCN | Epoch 032 Train Loss: 0.2244 | Val Loss: 0.2196\n",
      "GCN | Epoch 033 Train Loss: 0.2232 | Val Loss: 0.2192\n",
      "GCN | Epoch 034 Train Loss: 0.2229 | Val Loss: 0.2189\n",
      "GCN | Epoch 035 Train Loss: 0.2218 | Val Loss: 0.2238\n",
      "GCN | Epoch 036 Train Loss: 0.2212 | Val Loss: 0.2204\n",
      "GCN | Epoch 037 Train Loss: 0.2223 | Val Loss: 0.2166\n",
      "GCN | Epoch 038 Train Loss: 0.2226 | Val Loss: 0.2180\n",
      "GCN | Epoch 039 Train Loss: 0.2209 | Val Loss: 0.2187\n",
      "GCN | Epoch 040 Train Loss: 0.2198 | Val Loss: 0.2161\n",
      "GCN | Epoch 041 Train Loss: 0.2212 | Val Loss: 0.2158\n",
      "GCN | Epoch 042 Train Loss: 0.2200 | Val Loss: 0.2153\n",
      "GCN | Epoch 043 Train Loss: 0.2190 | Val Loss: 0.2167\n",
      "GCN | Epoch 044 Train Loss: 0.2212 | Val Loss: 0.2160\n",
      "GCN | Epoch 045 Train Loss: 0.2201 | Val Loss: 0.2155\n",
      "GCN | Epoch 046 Train Loss: 0.2189 | Val Loss: 0.2247\n",
      "GCN | Epoch 047 Train Loss: 0.2198 | Val Loss: 0.2163\n",
      "GCN | Epoch 048 Train Loss: 0.2187 | Val Loss: 0.2124\n",
      "GCN | Epoch 049 Train Loss: 0.2191 | Val Loss: 0.2148\n",
      "GCN | Epoch 050 Train Loss: 0.2175 | Val Loss: 0.2121\n",
      "GCN Test Loss: 0.2282\n",
      "Training GAT\n",
      "GAT | Epoch 001 Train Loss: 0.3460 | Val Loss: 0.2499\n",
      "GAT | Epoch 002 Train Loss: 0.2526 | Val Loss: 0.2394\n",
      "GAT | Epoch 003 Train Loss: 0.2455 | Val Loss: 0.2474\n",
      "GAT | Epoch 004 Train Loss: 0.2443 | Val Loss: 0.2378\n",
      "GAT | Epoch 005 Train Loss: 0.2438 | Val Loss: 0.2379\n",
      "GAT | Epoch 006 Train Loss: 0.2426 | Val Loss: 0.2365\n",
      "GAT | Epoch 007 Train Loss: 0.2405 | Val Loss: 0.2343\n",
      "GAT | Epoch 008 Train Loss: 0.2371 | Val Loss: 0.2284\n",
      "GAT | Epoch 009 Train Loss: 0.2340 | Val Loss: 0.2266\n",
      "GAT | Epoch 010 Train Loss: 0.2335 | Val Loss: 0.2317\n",
      "GAT | Epoch 011 Train Loss: 0.2319 | Val Loss: 0.2256\n",
      "GAT | Epoch 012 Train Loss: 0.2298 | Val Loss: 0.2269\n",
      "GAT | Epoch 013 Train Loss: 0.2300 | Val Loss: 0.2260\n",
      "GAT | Epoch 014 Train Loss: 0.2290 | Val Loss: 0.2234\n",
      "GAT | Epoch 015 Train Loss: 0.2291 | Val Loss: 0.2243\n",
      "GAT | Epoch 016 Train Loss: 0.2291 | Val Loss: 0.2286\n",
      "GAT | Epoch 017 Train Loss: 0.2283 | Val Loss: 0.2229\n",
      "GAT | Epoch 018 Train Loss: 0.2281 | Val Loss: 0.2241\n",
      "GAT | Epoch 019 Train Loss: 0.2271 | Val Loss: 0.2215\n",
      "GAT | Epoch 020 Train Loss: 0.2254 | Val Loss: 0.2208\n",
      "GAT | Epoch 021 Train Loss: 0.2260 | Val Loss: 0.2228\n",
      "GAT | Epoch 022 Train Loss: 0.2256 | Val Loss: 0.2281\n",
      "GAT | Epoch 023 Train Loss: 0.2271 | Val Loss: 0.2217\n",
      "GAT | Epoch 024 Train Loss: 0.2251 | Val Loss: 0.2225\n",
      "GAT | Epoch 025 Train Loss: 0.2240 | Val Loss: 0.2199\n",
      "GAT | Epoch 026 Train Loss: 0.2255 | Val Loss: 0.2197\n",
      "GAT | Epoch 027 Train Loss: 0.2237 | Val Loss: 0.2192\n",
      "GAT | Epoch 028 Train Loss: 0.2254 | Val Loss: 0.2190\n",
      "GAT | Epoch 029 Train Loss: 0.2229 | Val Loss: 0.2190\n",
      "GAT | Epoch 030 Train Loss: 0.2231 | Val Loss: 0.2197\n",
      "GAT | Epoch 031 Train Loss: 0.2229 | Val Loss: 0.2182\n",
      "GAT | Epoch 032 Train Loss: 0.2224 | Val Loss: 0.2176\n",
      "GAT | Epoch 033 Train Loss: 0.2227 | Val Loss: 0.2180\n",
      "GAT | Epoch 034 Train Loss: 0.2226 | Val Loss: 0.2178\n",
      "GAT | Epoch 035 Train Loss: 0.2216 | Val Loss: 0.2193\n",
      "GAT | Epoch 036 Train Loss: 0.2205 | Val Loss: 0.2167\n",
      "GAT | Epoch 037 Train Loss: 0.2210 | Val Loss: 0.2203\n",
      "GAT | Epoch 038 Train Loss: 0.2211 | Val Loss: 0.2170\n",
      "GAT | Epoch 039 Train Loss: 0.2207 | Val Loss: 0.2164\n",
      "GAT | Epoch 040 Train Loss: 0.2220 | Val Loss: 0.2170\n",
      "GAT | Epoch 041 Train Loss: 0.2203 | Val Loss: 0.2192\n",
      "GAT | Epoch 042 Train Loss: 0.2197 | Val Loss: 0.2157\n",
      "GAT | Epoch 043 Train Loss: 0.2195 | Val Loss: 0.2187\n",
      "GAT | Epoch 044 Train Loss: 0.2194 | Val Loss: 0.2155\n",
      "GAT | Epoch 045 Train Loss: 0.2193 | Val Loss: 0.2165\n",
      "GAT | Epoch 046 Train Loss: 0.2191 | Val Loss: 0.2169\n",
      "GAT | Epoch 047 Train Loss: 0.2202 | Val Loss: 0.2160\n",
      "GAT | Epoch 048 Train Loss: 0.2185 | Val Loss: 0.2155\n",
      "GAT | Epoch 049 Train Loss: 0.2194 | Val Loss: 0.2144\n",
      "GAT | Epoch 050 Train Loss: 0.2203 | Val Loss: 0.2161\n",
      "GAT Test Loss: 0.2308\n",
      "Summary of training:\n",
      "Model | Val Loss | Test Loss\n",
      "GCN  | 0.2121 | 0.2282\n",
      "GAT  | 0.2144 | 0.2308\n"
     ]
    }
   ],
   "source": [
    "sample_graph = train_dataset[0]\n",
    "in_channels = sample_graph.x.shape[1]\n",
    "out_channels = sample_graph.y.shape[0]\n",
    "results = {}\n",
    "\n",
    "for model_type in ['GCN', 'GAT']:\n",
    "    print(f\"Training {model_type}\")\n",
    "    model = GNNModel(\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels=CONFIG['hidden_channels'],\n",
    "        out_channels=out_channels,\n",
    "        model_type=model_type,\n",
    "        num_layers=CONFIG['num_layers'],\n",
    "        dropout=CONFIG['dropout']\n",
    "    ).to(CONFIG['device'])\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, CONFIG['epochs']+1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, CONFIG['device'])\n",
    "        val_loss = evaluate(model, val_loader, CONFIG['device'])\n",
    "        print(f\"{model_type} | Epoch {epoch:03d} Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_{model_type}.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG['patience']:\n",
    "                print(f\"Early stopping {model_type}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"best_{model_type}.pt\"))\n",
    "    test_loss = evaluate(model, test_loader, CONFIG['device'])\n",
    "    print(f\"{model_type} Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    results[model_type] = {'val_loss': best_val_loss, 'test_loss': test_loss}\n",
    "\n",
    "print(\"Summary of training:\")\n",
    "print(\"Model | Val Loss | Test Loss\")\n",
    "for model_type, res in results.items():\n",
    "    print(f\"{model_type:4s} | {res['val_loss']:.4f} | {res['test_loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
