{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcacac9",
   "metadata": {},
   "source": [
    "# Building Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1edbe6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rdkit in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2025.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from rdkit) (2.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from rdkit) (11.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install rdkit\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcd7f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (0.24.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (2.7.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.11.18)\n",
      "Requirement already satisfied: fsspec in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (7.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from torch-geometric) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->torch-geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\goisa\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "%pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52323a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from torch_geometric.utils import from_smiles\n",
    "\n",
    "CONFIG = {\n",
    "    'data_dir': './processed_tox21',\n",
    "    'hidden_channels': 128,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 0,\n",
    "    'epochs': 50,\n",
    "    'patience': 8,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Automatically detects if you have a GPU\n",
    "print(f\"Using device: {CONFIG['device']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb190d6a",
   "metadata": {},
   "source": [
    "Load data from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cfc6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6258 | Validation: 782 | Test: 783\n"
     ]
    }
   ],
   "source": [
    "def load_split(name):\n",
    "    path = os.path.join(CONFIG['data_dir'], f'tox21_{name}.pkl')\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train = load_split('train')\n",
    "data_validation = load_split('validation')\n",
    "data_test = load_split('test')\n",
    "\n",
    "print(f\"Train: {len(data_train['smiles'])} | Validation: {len(data_validation['smiles'])} | Test: {len(data_test['smiles'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff422e",
   "metadata": {},
   "source": [
    "Convert SMILES to GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5af06857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(smi, labels):\n",
    "    try:\n",
    "        data = from_smiles(smi)\n",
    "        data.y = torch.tensor(labels, dtype=torch.float)\n",
    "        return data\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_dataset(smiles_list, label_matrix):\n",
    "    dataset = []\n",
    "    for smi, lbl in zip(smiles_list, label_matrix):\n",
    "        g = build_graph(smi, lbl)\n",
    "        if g is not None:\n",
    "            dataset.append(g)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "873e1893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Data\n",
      "Train: 6258 | Validation: 782 | Test: 783\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(data_train['smiles'], data_train['labels'])\n",
    "validation_dataset = make_dataset(data_validation['smiles'], data_validation['labels'])\n",
    "test_dataset = make_dataset(data_test['smiles'], data_test['labels'])\n",
    "\n",
    "print(f\"Graphs Data\")\n",
    "print(f\"Train: {len(train_dataset)} | Validation: {len(validation_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eac301c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = CONFIG['batch_size'], shuffle = True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size = CONFIG['batch_size'])\n",
    "test_loader = DataLoader(test_dataset, batch_size = CONFIG['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed950470",
   "metadata": {},
   "source": [
    "Class for GNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49f58632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, model_type='GCN', num_layers=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        self.convs = nn.ModuleList()\n",
    "        if model_type == 'GCN':\n",
    "            # Aggregates information from neighboring atoms\n",
    "            self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "            for _ in range(num_layers-1):\n",
    "                self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        elif model_type == 'GAT':\n",
    "            # Learns to weight each neighbour\n",
    "            self.convs.append(GATConv(in_channels, hidden_channels, heads=4, concat=False))\n",
    "            for _ in range(num_layers-1):\n",
    "                self.convs.append(GATConv(hidden_channels, hidden_channels, heads=4, concat=False))\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'GCN' or 'GAT'\")\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels//2, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = torch.relu(x)\n",
    "            x = nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56812b35",
   "metadata": {},
   "source": [
    "Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99df133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_bce_loss(logits, labels):\n",
    "    mask = ~torch.isnan(labels)\n",
    "    if mask.sum() == 0:\n",
    "        return torch.tensor(0.0, device=logits.device)\n",
    "    labels_filled = torch.where(mask, labels, torch.zeros_like(labels))\n",
    "    loss = nn.BCEWithLogitsLoss(reduction='none')(logits, labels_filled)\n",
    "    loss = loss * mask.float()\n",
    "    return loss.sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25e1c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        loss = masked_bce_loss(logits, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2633cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            logits = model(data.x, data.edge_index, data.batch)\n",
    "            loss = masked_bce_loss(logits, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9439db8",
   "metadata": {},
   "source": [
    "Train and Evaluate GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b68009d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m patience_counter = \u001b[32m0\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, CONFIG[\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m]+\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     val_loss = evaluate(model, val_loader, CONFIG[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, device)\u001b[39m\n\u001b[32m      5\u001b[39m data = data.to(device)\n\u001b[32m      6\u001b[39m optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m loss = masked_bce_loss(logits, data.y)\n\u001b[32m      9\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mGNNModel.forward\u001b[39m\u001b[34m(self, x, edge_index, batch)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch):\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.convs:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m         x = torch.relu(x)\n\u001b[32m     31\u001b[39m         x = nn.functional.dropout(x, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:109\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m    107\u001b[39m idx = col \u001b[38;5;28;01mif\u001b[39;00m flow == \u001b[33m'\u001b[39m\u001b[33msource_to_target\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[32m    108\u001b[39m deg = scatter(edge_weight, idx, dim=\u001b[32m0\u001b[39m, dim_size=num_nodes, reduce=\u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m deg_inv_sqrt = \u001b[43mdeg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpow_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m deg_inv_sqrt.masked_fill_(deg_inv_sqrt == \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m), \u001b[32m0\u001b[39m)\n\u001b[32m    111\u001b[39m edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
      "\u001b[31mRuntimeError\u001b[39m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "sample_graph = train_dataset[0]\n",
    "in_channels = sample_graph.x.shape[1]\n",
    "out_channels = sample_graph.y.shape[0]\n",
    "results = {}\n",
    "\n",
    "for model_type in ['GCN', 'GAT']:\n",
    "    print(f\"Training {model_type}\")\n",
    "    model = GNNModel(\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels=CONFIG['hidden_channels'],\n",
    "        out_channels=out_channels,\n",
    "        model_type=model_type,\n",
    "        num_layers=CONFIG['num_layers'],\n",
    "        dropout=CONFIG['dropout']\n",
    "    ).to(CONFIG['device'])\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, CONFIG['epochs']+1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, CONFIG['device'])\n",
    "        val_loss = evaluate(model, val_loader, CONFIG['device'])\n",
    "        print(f\"{model_type} | Epoch {epoch:03d} Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.sate_dict(), f\"best_{model_type}.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG['patience']:\n",
    "                print(f\"Early stopping {model_type}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"best_{model_type}.pt\"))\n",
    "    test_loss = evaluate(model, test_loader, CONFIG['device'])\n",
    "    print(f\"{model_type} Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    results[model_type] = {'val_loss': best_val_loss, 'test_loss': test_loss}\n",
    "\n",
    "print(\"Summary of training:\")\n",
    "print(\"Model | Val Loss | Test Loss\")\n",
    "for model_type, res in results.items():\n",
    "    print(f\"{model_type:4s} | {res['val_loss']:.4f} | {res['test_loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
