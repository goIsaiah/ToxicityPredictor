{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcacac9",
   "metadata": {},
   "source": [
    "# Building Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1edbe6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in ./.venv/lib/python3.12/site-packages (2025.9.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from rdkit) (2.3.4)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from rdkit) (12.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rdkit\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd7f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in ./.venv/lib/python3.12/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch-geometric in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from torch-geometric) (3.13.1)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch-geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torch-geometric) (2.3.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./.venv/lib/python3.12/site-packages (from torch-geometric) (7.1.2)\n",
      "Requirement already satisfied: pyparsing in ./.venv/lib/python3.12/site-packages (from torch-geometric) (3.2.5)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from torch-geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from torch-geometric) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->torch-geometric) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->torch-geometric) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->torch-geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in ./.venv/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n",
    "%pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52323a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goisaiah/Visual Studio Code Projects/ToxicityPredictor/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from torch_geometric.utils import from_smiles\n",
    "import pandas as pd\n",
    "\n",
    "CONFIG = {\n",
    "    'data_dir': './processed_tox21',\n",
    "    'hidden_channels': 128,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 0,\n",
    "    'epochs': 50,\n",
    "    'patience': 8,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Automatically detects if you have a GPU\n",
    "print(f\"Using device: {CONFIG['device']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb190d6a",
   "metadata": {},
   "source": [
    "Load data from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfc6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6258 | Validation: 782 | Test: 783\n"
     ]
    }
   ],
   "source": [
    "def load_split(name):\n",
    "    path = os.path.join(CONFIG['data_dir'], f'tox21_{name}.pkl')\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train = load_split('train')\n",
    "data_validation = load_split('validation')\n",
    "data_test = load_split('test')\n",
    "\n",
    "print(f\"Train: {len(data_train['smiles'])} | Validation: {len(data_validation['smiles'])} | Test: {len(data_test['smiles'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff422e",
   "metadata": {},
   "source": [
    "Convert SMILES to GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af06857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(smi, labels):\n",
    "    try:\n",
    "        data = from_smiles(smi)\n",
    "        data.y = torch.tensor(labels, dtype=torch.float)\n",
    "        return data\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_dataset(smiles_list, label_matrix):\n",
    "    dataset = []\n",
    "    for smi, lbl in zip(smiles_list, label_matrix):\n",
    "        g = build_graph(smi, lbl)\n",
    "        if g is not None:\n",
    "            dataset.append(g)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873e1893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs Data\n",
      "Train: 6258 | Validation: 782 | Test: 783\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(data_train['smiles'], data_train['labels'])\n",
    "validation_dataset = make_dataset(data_validation['smiles'], data_validation['labels'])\n",
    "test_dataset = make_dataset(data_test['smiles'], data_test['labels'])\n",
    "\n",
    "print(f\"Graphs Data\")\n",
    "print(f\"Train: {len(train_dataset)} | Validation: {len(validation_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac301c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = CONFIG['batch_size'], shuffle = True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size = CONFIG['batch_size'])\n",
    "test_loader = DataLoader(test_dataset, batch_size = CONFIG['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed950470",
   "metadata": {},
   "source": [
    "Class for GNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f58632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, model_type='GCN', num_layers=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        self.convs = nn.ModuleList()\n",
    "        if model_type == 'GCN':\n",
    "            # Aggregates information from neighboring atoms\n",
    "            self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "            for _ in range(num_layers-1):\n",
    "                self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        elif model_type == 'GAT':\n",
    "            # Learns to weight each neighbour\n",
    "            self.convs.append(GATConv(in_channels, hidden_channels, heads=4, concat=False))\n",
    "            for _ in range(num_layers-1):\n",
    "                self.convs.append(GATConv(hidden_channels, hidden_channels, heads=4, concat=False))\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'GCN' or 'GAT'\")\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels//2, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = torch.relu(x)\n",
    "            x = nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56812b35",
   "metadata": {},
   "source": [
    "Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99df133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_bce_loss(logits, labels):\n",
    "    mask = ~torch.isnan(labels)\n",
    "    if mask.sum() == 0:\n",
    "        return torch.tensor(0.0, device=logits.device)\n",
    "    labels_filled = torch.where(mask, labels, torch.zeros_like(labels))\n",
    "    loss = nn.BCEWithLogitsLoss(reduction='none')(logits, labels_filled)\n",
    "    loss = loss * mask.float()\n",
    "    return loss.sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e1c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        data.x = data.x.to(torch.float)\n",
    "        data.edge_index = data.edge_index.to(torch.long)\n",
    "        if hasattr(data, \"edge_attr\") and data.edge_attr is not None:\n",
    "            data.edge_attr = data.edge_attr.to(torch.float)\n",
    "        data.y = data.y.to(torch.float)\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        if data.y.dim() == 1:\n",
    "            data.y = data.y.view(-1, logits.size(1))\n",
    "\n",
    "        loss = masked_bce_loss(logits, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2633cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data.x = data.x.to(torch.float)\n",
    "            data.edge_index = data.edge_index.to(torch.long)\n",
    "            if hasattr(data, \"edge_attr\") and data.edge_attr is not None:\n",
    "                data.edge_attr = data.edge_attr.to(torch.float)\n",
    "            data.y = data.y.to(torch.float)\n",
    "\n",
    "            data = data.to(device)\n",
    "            \n",
    "            logits = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "            if data.y.dim() == 1:\n",
    "                data.y = data.y.view(-1, logits.size(1))\n",
    "\n",
    "            loss = masked_bce_loss(logits, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9439db8",
   "metadata": {},
   "source": [
    "Train and Evaluate GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68009d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN\n",
      "GCN | Epoch 001 Train Loss: 0.3045 | Val Loss: 0.2503\n",
      "GCN | Epoch 002 Train Loss: 0.2543 | Val Loss: 0.2434\n",
      "GCN | Epoch 003 Train Loss: 0.2490 | Val Loss: 0.2393\n",
      "GCN | Epoch 004 Train Loss: 0.2446 | Val Loss: 0.2488\n",
      "GCN | Epoch 005 Train Loss: 0.2428 | Val Loss: 0.2381\n",
      "GCN | Epoch 006 Train Loss: 0.2397 | Val Loss: 0.2351\n",
      "GCN | Epoch 007 Train Loss: 0.2383 | Val Loss: 0.2316\n",
      "GCN | Epoch 008 Train Loss: 0.2362 | Val Loss: 0.2301\n",
      "GCN | Epoch 009 Train Loss: 0.2334 | Val Loss: 0.2275\n",
      "GCN | Epoch 010 Train Loss: 0.2319 | Val Loss: 0.2262\n",
      "GCN | Epoch 011 Train Loss: 0.2316 | Val Loss: 0.2255\n",
      "GCN | Epoch 012 Train Loss: 0.2326 | Val Loss: 0.2272\n",
      "GCN | Epoch 013 Train Loss: 0.2314 | Val Loss: 0.2260\n",
      "GCN | Epoch 014 Train Loss: 0.2291 | Val Loss: 0.2240\n",
      "GCN | Epoch 015 Train Loss: 0.2313 | Val Loss: 0.2241\n",
      "GCN | Epoch 016 Train Loss: 0.2300 | Val Loss: 0.2241\n",
      "GCN | Epoch 017 Train Loss: 0.2289 | Val Loss: 0.2270\n",
      "GCN | Epoch 018 Train Loss: 0.2288 | Val Loss: 0.2281\n",
      "GCN | Epoch 019 Train Loss: 0.2284 | Val Loss: 0.2228\n",
      "GCN | Epoch 020 Train Loss: 0.2312 | Val Loss: 0.2232\n",
      "GCN | Epoch 021 Train Loss: 0.2266 | Val Loss: 0.2218\n",
      "GCN | Epoch 022 Train Loss: 0.2268 | Val Loss: 0.2214\n",
      "GCN | Epoch 023 Train Loss: 0.2252 | Val Loss: 0.2213\n",
      "GCN | Epoch 024 Train Loss: 0.2275 | Val Loss: 0.2204\n",
      "GCN | Epoch 025 Train Loss: 0.2257 | Val Loss: 0.2197\n",
      "GCN | Epoch 026 Train Loss: 0.2245 | Val Loss: 0.2207\n",
      "GCN | Epoch 027 Train Loss: 0.2235 | Val Loss: 0.2210\n",
      "GCN | Epoch 028 Train Loss: 0.2252 | Val Loss: 0.2191\n",
      "GCN | Epoch 029 Train Loss: 0.2242 | Val Loss: 0.2210\n",
      "GCN | Epoch 030 Train Loss: 0.2239 | Val Loss: 0.2183\n",
      "GCN | Epoch 031 Train Loss: 0.2226 | Val Loss: 0.2199\n",
      "GCN | Epoch 032 Train Loss: 0.2243 | Val Loss: 0.2215\n",
      "GCN | Epoch 033 Train Loss: 0.2221 | Val Loss: 0.2181\n",
      "GCN | Epoch 034 Train Loss: 0.2231 | Val Loss: 0.2178\n",
      "GCN | Epoch 035 Train Loss: 0.2214 | Val Loss: 0.2162\n",
      "GCN | Epoch 036 Train Loss: 0.2228 | Val Loss: 0.2198\n",
      "GCN | Epoch 037 Train Loss: 0.2232 | Val Loss: 0.2189\n",
      "GCN | Epoch 038 Train Loss: 0.2217 | Val Loss: 0.2185\n",
      "GCN | Epoch 039 Train Loss: 0.2198 | Val Loss: 0.2206\n",
      "GCN | Epoch 040 Train Loss: 0.2217 | Val Loss: 0.2168\n",
      "GCN | Epoch 041 Train Loss: 0.2212 | Val Loss: 0.2154\n",
      "GCN | Epoch 042 Train Loss: 0.2200 | Val Loss: 0.2162\n",
      "GCN | Epoch 043 Train Loss: 0.2210 | Val Loss: 0.2182\n",
      "GCN | Epoch 044 Train Loss: 0.2188 | Val Loss: 0.2222\n",
      "GCN | Epoch 045 Train Loss: 0.2197 | Val Loss: 0.2190\n",
      "GCN | Epoch 046 Train Loss: 0.2175 | Val Loss: 0.2159\n",
      "GCN | Epoch 047 Train Loss: 0.2185 | Val Loss: 0.2128\n",
      "GCN | Epoch 048 Train Loss: 0.2187 | Val Loss: 0.2153\n",
      "GCN | Epoch 049 Train Loss: 0.2175 | Val Loss: 0.2130\n",
      "GCN | Epoch 050 Train Loss: 0.2181 | Val Loss: 0.2110\n",
      "GCN Test Loss: 0.2311\n",
      "Training GAT\n",
      "GAT | Epoch 001 Train Loss: 0.3436 | Val Loss: 0.2498\n",
      "GAT | Epoch 002 Train Loss: 0.2507 | Val Loss: 0.2383\n",
      "GAT | Epoch 003 Train Loss: 0.2454 | Val Loss: 0.2374\n",
      "GAT | Epoch 004 Train Loss: 0.2423 | Val Loss: 0.2367\n",
      "GAT | Epoch 005 Train Loss: 0.2413 | Val Loss: 0.2358\n",
      "GAT | Epoch 006 Train Loss: 0.2395 | Val Loss: 0.2325\n",
      "GAT | Epoch 007 Train Loss: 0.2358 | Val Loss: 0.2293\n",
      "GAT | Epoch 008 Train Loss: 0.2316 | Val Loss: 0.2267\n",
      "GAT | Epoch 009 Train Loss: 0.2315 | Val Loss: 0.2253\n",
      "GAT | Epoch 010 Train Loss: 0.2308 | Val Loss: 0.2236\n",
      "GAT | Epoch 011 Train Loss: 0.2291 | Val Loss: 0.2219\n",
      "GAT | Epoch 012 Train Loss: 0.2279 | Val Loss: 0.2225\n",
      "GAT | Epoch 013 Train Loss: 0.2290 | Val Loss: 0.2216\n",
      "GAT | Epoch 014 Train Loss: 0.2280 | Val Loss: 0.2208\n",
      "GAT | Epoch 015 Train Loss: 0.2278 | Val Loss: 0.2240\n",
      "GAT | Epoch 016 Train Loss: 0.2270 | Val Loss: 0.2196\n",
      "GAT | Epoch 017 Train Loss: 0.2243 | Val Loss: 0.2217\n",
      "GAT | Epoch 018 Train Loss: 0.2248 | Val Loss: 0.2200\n",
      "GAT | Epoch 019 Train Loss: 0.2246 | Val Loss: 0.2212\n",
      "GAT | Epoch 020 Train Loss: 0.2238 | Val Loss: 0.2183\n",
      "GAT | Epoch 021 Train Loss: 0.2228 | Val Loss: 0.2162\n",
      "GAT | Epoch 022 Train Loss: 0.2238 | Val Loss: 0.2175\n",
      "GAT | Epoch 023 Train Loss: 0.2227 | Val Loss: 0.2181\n",
      "GAT | Epoch 024 Train Loss: 0.2228 | Val Loss: 0.2156\n",
      "GAT | Epoch 025 Train Loss: 0.2211 | Val Loss: 0.2156\n",
      "GAT | Epoch 026 Train Loss: 0.2220 | Val Loss: 0.2153\n",
      "GAT | Epoch 027 Train Loss: 0.2196 | Val Loss: 0.2192\n",
      "GAT | Epoch 028 Train Loss: 0.2202 | Val Loss: 0.2151\n",
      "GAT | Epoch 029 Train Loss: 0.2189 | Val Loss: 0.2138\n",
      "GAT | Epoch 030 Train Loss: 0.2186 | Val Loss: 0.2143\n",
      "GAT | Epoch 031 Train Loss: 0.2183 | Val Loss: 0.2154\n",
      "GAT | Epoch 032 Train Loss: 0.2191 | Val Loss: 0.2137\n",
      "GAT | Epoch 033 Train Loss: 0.2176 | Val Loss: 0.2118\n",
      "GAT | Epoch 034 Train Loss: 0.2187 | Val Loss: 0.2151\n",
      "GAT | Epoch 035 Train Loss: 0.2181 | Val Loss: 0.2119\n",
      "GAT | Epoch 036 Train Loss: 0.2174 | Val Loss: 0.2111\n",
      "GAT | Epoch 037 Train Loss: 0.2185 | Val Loss: 0.2374\n",
      "GAT | Epoch 038 Train Loss: 0.2184 | Val Loss: 0.2121\n",
      "GAT | Epoch 039 Train Loss: 0.2162 | Val Loss: 0.2124\n",
      "GAT | Epoch 040 Train Loss: 0.2165 | Val Loss: 0.2108\n",
      "GAT | Epoch 041 Train Loss: 0.2156 | Val Loss: 0.2140\n",
      "GAT | Epoch 042 Train Loss: 0.2179 | Val Loss: 0.2101\n",
      "GAT | Epoch 043 Train Loss: 0.2155 | Val Loss: 0.2103\n",
      "GAT | Epoch 044 Train Loss: 0.2152 | Val Loss: 0.2128\n",
      "GAT | Epoch 045 Train Loss: 0.2144 | Val Loss: 0.2122\n",
      "GAT | Epoch 046 Train Loss: 0.2150 | Val Loss: 0.2111\n",
      "GAT | Epoch 047 Train Loss: 0.2140 | Val Loss: 0.2085\n",
      "GAT | Epoch 048 Train Loss: 0.2153 | Val Loss: 0.2096\n",
      "GAT | Epoch 049 Train Loss: 0.2138 | Val Loss: 0.2096\n",
      "GAT | Epoch 050 Train Loss: 0.2143 | Val Loss: 0.2089\n",
      "GAT Test Loss: 0.2265\n",
      "Summary of training:\n",
      "Model | Val Loss | Test Loss\n",
      "GCN  | 0.2110 | 0.2311\n",
      "GAT  | 0.2085 | 0.2265\n"
     ]
    }
   ],
   "source": [
    "sample_graph = train_dataset[0]\n",
    "in_channels = sample_graph.x.shape[1]\n",
    "out_channels = sample_graph.y.shape[0]\n",
    "results = {}\n",
    "results_rows = []\n",
    "\n",
    "for model_type in ['GCN', 'GAT']:\n",
    "    print(f\"Training {model_type}\")\n",
    "    model = GNNModel(\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels=CONFIG['hidden_channels'],\n",
    "        out_channels=out_channels,\n",
    "        model_type=model_type,\n",
    "        num_layers=CONFIG['num_layers'],\n",
    "        dropout=CONFIG['dropout']\n",
    "    ).to(CONFIG['device'])\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, CONFIG['epochs']+1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, CONFIG['device'])\n",
    "        val_loss = evaluate(model, val_loader, CONFIG['device'])\n",
    "\n",
    "        results_rows.append({\n",
    "            \"Model\": model_type,\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": round(train_loss, 4),\n",
    "            \"Val Loss\": round(val_loss, 4)\n",
    "        })\n",
    "\n",
    "        print(f\"{model_type} | Epoch {epoch:03d} Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_{model_type}.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG['patience']:\n",
    "                print(f\"Early stopping {model_type}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"best_{model_type}.pt\"))\n",
    "    test_loss = evaluate(model, test_loader, CONFIG['device'])\n",
    "    print(f\"{model_type} Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    results_rows.append({\n",
    "        \"Model\": model_type,\n",
    "        \"Epoch\": \"Best\",\n",
    "        \"Train Loss\": None,\n",
    "        \"Val Loss\": round(test_loss, 4),\n",
    "    })\n",
    "\n",
    "    results[model_type] = {'val_loss': best_val_loss, 'test_loss': test_loss}\n",
    "\n",
    "print(\"Summary of training:\")\n",
    "print(\"Model | Val Loss | Test Loss\")\n",
    "for model_type, res in results.items():\n",
    "    print(f\"{model_type:4s} | {res['val_loss']:.4f} | {res['test_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffb26e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>0.2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.2393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2446</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GAT</td>\n",
       "      <td>47</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GAT</td>\n",
       "      <td>48</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GAT</td>\n",
       "      <td>49</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GAT</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>GAT</td>\n",
       "      <td>Best</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Epoch  Train Loss  Val Loss\n",
       "0     GCN     1      0.3045    0.2503\n",
       "1     GCN     2      0.2543    0.2434\n",
       "2     GCN     3      0.2490    0.2393\n",
       "3     GCN     4      0.2446    0.2488\n",
       "4     GCN     5      0.2428    0.2381\n",
       "..    ...   ...         ...       ...\n",
       "97    GAT    47      0.2140    0.2085\n",
       "98    GAT    48      0.2153    0.2096\n",
       "99    GAT    49      0.2138    0.2096\n",
       "100   GAT    50      0.2143    0.2089\n",
       "101   GAT  Best         NaN    0.2265\n",
       "\n",
       "[102 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results_rows)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
